{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bayhaqy/Machine-Learning-Courses/blob/main/Classification_Iris_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification - Iris Prediction"
      ],
      "metadata": {
        "id": "PZNvz8efIBkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iris dataset is famous flower data set which was introduced in 1936. It is multivariate classification. This data comes from [UCI Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
        "\n",
        "![Iris Images](https://machinelearninghd.com/wp-content/uploads/2021/03/iris-dataset.png \"Iris Images\")\n",
        "\n",
        "![Iris Images](https://www.integratedots.com/wp-content/uploads/2019/06/iris_petal-sepal-e1560211020463.png \"Iris Images\")\n",
        "\n",
        "Iris dataset is taken from Sir R.A. Fisher paper for pattern recognition literature. It is also known as Andersonâ€™s Iris data set as Edge Anderson originally collected the data to quantify the variation of Iris flowers of there different class. These class are class Iris-Setosa, Iris-Versicolour, Iris-Virginica with attributes as Sepal Length, Sepal Width, Petal Length and Petal Width in centimeters."
      ],
      "metadata": {
        "id": "w73fselufSxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Gather"
      ],
      "metadata": {
        "id": "9_O8-fYy4he4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "57Y_zc2_4oLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris(as_frame=True)\n",
        "iris"
      ],
      "metadata": {
        "id": "8tdhvrp9W02h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the iris data\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add a target column to the DataFrame\n",
        "df['Target'] = iris['target']\n",
        "\n",
        "# Translate the target\n",
        "df['Target'] = df['Target'].apply(lambda x: iris['target_names'][x])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LvBn9k2C4nJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Target'], axis=1)\n",
        "y = df['Target']\n",
        "display(X)\n",
        "display(y)"
      ],
      "metadata": {
        "id": "TaLlF6W2ZJBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "wavzLe7k6z1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.describe())"
      ],
      "metadata": {
        "id": "gWH9z3IEsuUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.info())"
      ],
      "metadata": {
        "id": "JT04lrGOswJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ZLA2WmOHsba9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Plot for Relation for each data\n",
        "fig, ax = plt.subplots(3, 2, figsize=(12, 10))\n",
        "ax = ax.flatten()\n",
        "fig.suptitle('Iris Dataset')\n",
        "for i, combination in enumerate(itertools.combinations(list(X), 2)):\n",
        "    col1, col2 = combination\n",
        "    for species in iris['target_names']:\n",
        "        spec = X[y == species]\n",
        "        ax[i].scatter(spec[col1], spec[col2], label=species)\n",
        "    ax[i].set_xlabel(col1)\n",
        "    ax[i].set_ylabel(col2)\n",
        "    ax[i].legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y0kA2MExYqqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df,hue=\"Target\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RV8ayWLys9Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(edgecolor='red', linewidth=1.2)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(12,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kWRoSihkAdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(2,2,1)\n",
        "sns.violinplot(x='Target', y = 'sepal length (cm)', data=df)\n",
        "plt.subplot(2,2,2)\n",
        "sns.violinplot(x='Target', y = 'sepal width (cm)', data=df)\n",
        "plt.subplot(2,2,3)\n",
        "sns.violinplot(x='Target', y = 'petal length (cm)', data=df)\n",
        "plt.subplot(2,2,4)\n",
        "sns.violinplot(x='Target', y = 'petal width (cm)', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hfILsojIh0dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of Target\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.countplot(data=df, x='Target')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Target')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zOwRfUcB6Q1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
        "\n",
        "# Sepal Length\n",
        "data_plot = df.pivot_table(index='Target', values='sepal length (cm)', aggfunc=np.mean)\n",
        "data_plot.plot(kind='bar', ax=axes[0, 0])\n",
        "axes[0, 0].set_xlabel('Target')\n",
        "axes[0, 0].set_ylabel('sepal length (cm)')\n",
        "axes[0, 0].set_title('Target and sepal length Analysis')\n",
        "axes[0, 0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Sepal Width\n",
        "data_plot = df.pivot_table(index='Target', values='sepal width (cm)', aggfunc=np.mean)\n",
        "data_plot.plot(kind='bar', ax=axes[0, 1])\n",
        "axes[0, 1].set_xlabel('Target')\n",
        "axes[0, 1].set_ylabel('sepal width (cm)')\n",
        "axes[0, 1].set_title('Target and sepal width Analysis')\n",
        "axes[0, 1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Petal Length\n",
        "data_plot = df.pivot_table(index='Target', values='petal length (cm)', aggfunc=np.mean)\n",
        "data_plot.plot(kind='bar', ax=axes[1, 0])\n",
        "axes[1, 0].set_xlabel('Target')\n",
        "axes[1, 0].set_ylabel('petal length (cm)')\n",
        "axes[1, 0].set_title('Target and petal length Analysis')\n",
        "axes[1, 0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Petal Width\n",
        "data_plot = df.pivot_table(index='Target', values='petal width (cm)', aggfunc=np.mean)\n",
        "data_plot.plot(kind='bar', ax=axes[1, 1])\n",
        "axes[1, 1].set_xlabel('Target')\n",
        "axes[1, 1].set_ylabel('petal width (cm)')\n",
        "axes[1, 1].set_title('Target and petal width Analysis')\n",
        "axes[1, 1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "04Q4ej3lmvN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "zhL1yuLr4wLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bql6jVN14zdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "77S0SDyh8Rq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "TuoxtRm-5AX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "if9OygAM5DjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE3gaKk7UpEV"
      },
      "source": [
        "model = SVC()\n",
        "#model = GaussianNB()\n",
        "\n",
        "# Train the algorithm with training data and training output\n",
        "y_pred = model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate score\n",
        "print(\"Model score: \", model.score(X_train, y_train))\n",
        "print(\"Test Accuracy: \", model.score(X_test, y_test))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "# Generate a classification report to evaluate precision, recall, and F1-score\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the models\n",
        "models = {\n",
        "    'SVC': SVC(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "    'GaussianNB': GaussianNB()\n",
        "}\n",
        "\n",
        "best_model_name = None\n",
        "best_score = float('0.0')\n",
        "print(best_score)\n",
        "\n",
        "# Print the results\n",
        "print('Model | Accuracy')\n",
        "print('-------|-------')\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    train_score = model.score(X_train, y_train)\n",
        "\n",
        "    print('{} | {:.4f} | {:.4f}'.format(name, acc_score, train_score))\n",
        "\n",
        "    scores = acc_score + train_score\n",
        "\n",
        "    # Update the best model if needed\n",
        "    if scores > best_score:\n",
        "        best_score = scores\n",
        "        best_model = model\n",
        "        best_model_name = name\n",
        "\n",
        "# Print the best model\n",
        "print('The best model is: {}'.format(best_model_name))"
      ],
      "metadata": {
        "id": "-t4TILrb5mn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "\n",
        "pickle.dump(best_model, open(\"model.pkl\", \"wb\"))\n",
        "joblib.dump(best_model, \"model.sav\")"
      ],
      "metadata": {
        "id": "EToJzgw35HdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "FSelyZQtq-ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "6EF7AUjIt_Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the exported model\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "#model = joblib.load('model.sav')\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "Zp1ZO5BAt_Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Predict"
      ],
      "metadata": {
        "id": "rGbaHqiAt_Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "X_new = df.sample(2)\n",
        "display(X_new)\n",
        "\n",
        "X_new = X_new.drop(['Target'], axis=1)\n",
        "\n",
        "values = X_new.values  # Extract the values as a NumPy array\n",
        "\n",
        "# Convert the NumPy array to a JSON list\n",
        "values = json.dumps(values.tolist())\n",
        "\n",
        "display(values)"
      ],
      "metadata": {
        "id": "FQeXDx7OrCFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction from new data point\n",
        "\n",
        "# new data point\n",
        "#X_new = np.array([[5.4, 3.4, 1.5, 0.4]])\n",
        "X_new = np.array([[6.4, 2.8, 5.6, 2.2]])\n",
        "\n",
        "# Assuming X_new contains data for sepal length, sepal width, petal length, and petal width\n",
        "X_new = pd.DataFrame(X_new, columns=iris['feature_names'])\n",
        "\n",
        "display('X_new : ', X_new)"
      ],
      "metadata": {
        "id": "sPlvE7nyv4rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on the transformed new data point\n",
        "prediction = model.predict(X_new)\n",
        "print('prediction : ', prediction[0])"
      ],
      "metadata": {
        "id": "RS_TwRmvt_Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment"
      ],
      "metadata": {
        "id": "fF35vEEI5Iu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FastAPI Apps 1"
      ],
      "metadata": {
        "id": "JNM1fGG7AEPv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sWUbNKGW9ZX"
      },
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel, conlist\n",
        "from typing import List\n",
        "\n",
        "class Iris(BaseModel):\n",
        "    data: List[conlist(float, min_items=4, max_items=4)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi --quiet"
      ],
      "metadata": {
        "id": "pCLgveZ8-oDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpFW8OAV2r3"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        "from fastapi import FastAPI\n",
        "from models import Iris\n",
        "\n",
        "app = FastAPI(title=\"Iris - ML Models as API on Google Colab\", description=\"Iris with FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "# # Initialize logging\n",
        "# my_logger = logging.getLogger()\n",
        "# my_logger.setLevel(logging.DEBUG)\n",
        "# logging.basicConfig(level=logging.DEBUG, filename='logs.log')\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "  return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "model = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
        "\n",
        "@app.post(\"/api\", tags=[\"prediction\"])\n",
        "async def get_predictions(iris: Iris):\n",
        "    try:\n",
        "        print('input :', iris)\n",
        "        data = dict(iris)['data']\n",
        "        print('Data : ', data)\n",
        "#        iris_types = {\n",
        "#            0: 'setosa',\n",
        "#            1: 'versicolor',\n",
        "#            2: 'virginica'\n",
        "#        }\n",
        "#        prediction = list(map(lambda x: iris_types[x], model.predict(data).tolist()))\n",
        "\n",
        "        feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
        "        data = pd.DataFrame(data, columns=feature_names)\n",
        "#        prediction = list(model.predict(data).tolist())\n",
        "        prediction = model.predict(data).tolist()\n",
        "        print('Prediction : ', prediction)\n",
        "        log_proba = model.predict_log_proba(data).tolist()\n",
        "        print('log_proba : ', log_proba)\n",
        "        return {\"prediction\": prediction, \"log_proba\": log_proba}\n",
        "    except:\n",
        "        my_logger.error(\"Something went wrong!\")\n",
        "        return {\"prediction\": \"error\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://c0ab-35-196-186-183.ngrok-free.app/api' -X POST -H 'accept: application/json' -H 'Content-Type: application/json' -d '{\"data\": [[6.5, 3.0, 5.2, 2.0], [5.5, 2.3, 4.0, 1.3]]}'"
      ],
      "metadata": {
        "id": "usZ0mEg2Gu1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FastAPI Apps 2"
      ],
      "metadata": {
        "id": "A-YDkclOTk1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Iris(BaseModel):\n",
        "    sepal_length: float\n",
        "    sepal_width: float\n",
        "    petal_length: float\n",
        "    petal_width: float"
      ],
      "metadata": {
        "id": "_whyW26EARZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile iris_classifier.py\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from models import Iris\n",
        "\n",
        "class IrisClassifier:\n",
        "    def __init__(self):\n",
        "        self.X, self.y = load_iris(return_X_y=True)\n",
        "        self.clf = self.train_model()\n",
        "        self.iris_type = {\n",
        "            0: 'setosa',\n",
        "            1: 'versicolor',\n",
        "            2: 'virginica'\n",
        "        }\n",
        "\n",
        "    def train_model(self) -> LogisticRegression:\n",
        "        return LogisticRegression(solver='lbfgs',\n",
        "                                  max_iter=1000,\n",
        "                                  multi_class='multinomial').fit(self.X, self.y)\n",
        "\n",
        "    def classify_iris(self, iris: Iris):\n",
        "        X = [iris.sepal_length, iris.sepal_width, iris.petal_length, iris.petal_width]\n",
        "        prediction = self.clf.predict_proba([X])\n",
        "        return {'class': self.iris_type[np.argmax(prediction)],\n",
        "                'probability': round(max(prediction[0]), 2)}"
      ],
      "metadata": {
        "id": "tylMnFHpAXWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir router"
      ],
      "metadata": {
        "id": "Grvb3ERTA9WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile router/iris_classifier_router.py\n",
        "from fastapi import APIRouter\n",
        "from starlette.responses import JSONResponse\n",
        "\n",
        "from iris_classifier import IrisClassifier\n",
        "from models import Iris\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "@router.post('/classify_iris')\n",
        "def extract_name(iris_features: Iris):\n",
        "    iris_classifier = IrisClassifier()\n",
        "    return JSONResponse(iris_classifier.classify_iris(iris_features))"
      ],
      "metadata": {
        "id": "5ljSd2p2AuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi --quiet"
      ],
      "metadata": {
        "id": "fwVO1kwsByPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from router import iris_classifier_router\n",
        "\n",
        "app = FastAPI()\n",
        "app.include_router(iris_classifier_router.router, prefix='/iris')\n",
        "\n",
        "\n",
        "@app.get('/healthcheck', status_code=200)\n",
        "async def healthcheck():\n",
        "    return 'Iris classifier is all ready to go!'"
      ],
      "metadata": {
        "id": "N5oCFrd4BHwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://3794-35-194-129-220.ngrok-free.app/iris/classify_iris' -X POST -H 'Content-Type: application/json' -d '{\"sepal_length\": 5,\"sepal_width\": 2,\"petal_length\": 3,\"petal_width\": 4}'"
      ],
      "metadata": {
        "id": "Uw6Qs-TaD6cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ColabCode and Ngrok"
      ],
      "metadata": {
        "id": "fJ2mmw8ZAJ7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colabcode --quiet"
      ],
      "metadata": {
        "id": "DXSGPgmL-w9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "#2Sw7AbaYbnCEgpgbr0r3wZc4oni_6fRFwFQnBwoATB9LwC35B"
      ],
      "metadata": {
        "id": "Ehq7ocLZEZvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MkAOOTsy7hU"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIJus1C1y7hV"
      },
      "source": [
        "server.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streamlit Apps"
      ],
      "metadata": {
        "id": "O8d-ebOmafi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q"
      ],
      "metadata": {
        "id": "4LdIGj6AavAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prediction.py\n",
        "\n",
        "import joblib\n",
        "\n",
        "def predict(data):\n",
        "  clf = joblib.load('model.sav')\n",
        "  return clf.predict(data)"
      ],
      "metadata": {
        "id": "GHuxF2MghqnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prediction import predict\n",
        "\n",
        "st.title('Classifying Iris Flowers')\n",
        "st.markdown('Toy model to play to classify iris flowers into \\\n",
        "setosa, versicolor, virginica')\n",
        "\n",
        "st.header('Plant Features')\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "  st.text('Sepal characteristics')\n",
        "  sepal_l = st.slider('Sepal lenght (cm)', 1.0, 8.0, 0.5)\n",
        "  sepal_w = st.slider('Sepal width (cm)', 2.0, 4.4, 0.5)\n",
        "\n",
        "with col2:\n",
        "  st.text('Pepal characteristics')\n",
        "  petal_l = st.slider('Petal lenght (cm)', 1.0, 7.0, 0.5)\n",
        "  petal_w = st.slider('Petal width (cm)', 0.1, 2.5, 0.5)\n",
        "\n",
        "if st.button('Predict type of Iris'):\n",
        "  result = predict(np.array([[sepal_l, sepal_w, petal_l, petal_w]]))\n",
        "  st.text(result[0])"
      ],
      "metadata": {
        "id": "pAbvrheKaxqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit config show"
      ],
      "metadata": {
        "id": "gEXDd_pzlXrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run App { vertical-output: true }\n",
        "#print(\"You will see real time app logs below.\\nPaste the resulting IP address into the website's input field.\")\n",
        "#!streamlit run /content/app.py --server.port 8000 &>/content/logs.txt & npx localtunnel --port 8000 & curl ipv4.icanhazip.com;  tail -f /content/logs.txt &"
      ],
      "metadata": {
        "id": "LeXDV4yPc4rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py --server.port 8000 &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "ia35YZXZ3WbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com;  cat /content/logs.txt &"
      ],
      "metadata": {
        "id": "XoBmm9fzdxHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LocalTunnel"
      ],
      "metadata": {
        "id": "BJMbHNWmgZo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel -q"
      ],
      "metadata": {
        "id": "CrDjXpcJa2Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8000"
      ],
      "metadata": {
        "id": "4DvoU_8TdEDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pyngrok"
      ],
      "metadata": {
        "id": "hoZSiBQtg8e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n",
        "import getpass\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "#2Sw7AbaYbnCEgpgbr0r3wZc4oni_6fRFwFQnBwoATB9LwC35B"
      ],
      "metadata": {
        "id": "C29pYb3FTE63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an http ngrok tunnel\n",
        "connection_string = ngrok.connect(8000, \"http\").public_url\n",
        "print(\"Once server is up and says Running on local URL:  http://0.0.0.0:8000, click on this link, then click on Visit Site: %s\" % connection_string)"
      ],
      "metadata": {
        "id": "Tq6JjGl5hFe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can kill old ngrok + generate and try again\n",
        "do_kill = False\n",
        "if do_kill:\n",
        "  !pkill -f generate --signal 9\n",
        "  !pkill -f frpc_linux_amd --signal 9\n",
        "  !pkill -f ngrok --signal 9\n",
        "\n",
        "!killall ngrok\n",
        "!killall streamlit"
      ],
      "metadata": {
        "id": "5NRlvV6hTIpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}